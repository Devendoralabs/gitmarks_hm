<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-type" content="text/html; charset=utf-8">
	<title>dotbot | DotNetDotCom.org</title>
	<link rel="stylesheet" type="text/css" href="./css/default.css" />
</head>
<body>
	<div id="container">
		<div id="header">
			<div id="left">
			</div>
			<div id="right">
			</div>
		</div>
		<div id="content">
			<h1>Dotbot</h1>
			<h2>Hi!  Thanks for letting us crawl you!</h2>
			<p>We are just a few Seattle based guys trying to figure out how to make internet data as open as possible. You should be able to find everything you are looking for below. If not feel free to <a href="#cont">contact us</a>. Happy Surfing!

				<div id="happy-spider">
					<img src="img/happy-spider.jpg" alt="Happy Spider">
					<br />
				</div>

				<hr>
				<ul>
					<li><a href="#info">Information on how to block our crawler.</a> <span class="note">(Hint, it doesn't involve legal action)</span></li>
					<li><a href="#verify">Process for verifying our user-agent.</a> <span class="note">(Who is on first)</span></li>
					<li><a href="#purpose">Our purpose and goal.</a> <span class="note">(Yes we have one and no it doesn't involve spam)</span></li>
					<li><a href="#tech">Our technology.</a> <span class="note">(Thanks open source!)</span></li>
					<li><a href="#inde">Downloadable index of the internet.</a> <span class="note">(Can you say big file?)</span></li>
					<li><a href="#stat">Internet statistics and free index of the web.</a> <span class="note">(It's your internet, take a look)</span></li>
					<li><a href="#cont">Contact information.</a> <span class="note">(Did your site confuse our crawler? Did our mascot scare you? Know any good jokes?)</span></li>
				</ul>
				<hr>
				<div id="info">
					<h2>Information on how to block our crawler</h2>
					<ol>
						<li>First and foremost, curse our name. Trust us, it will feel good. Now breathe gently...</li>
						<li>Create a simple text file named <a href="http://www.robotstxt.org/robotstxt.html">robots.txt</a> and place it in your server's root directory. (http://www.yoursite.com/   &laquo;-- Right There!)</li>
						<li>Add the following code to your robots.txt file:</li>
						<div class="official">			
							User-agent: dotbot <br />
							Disallow: / <br />
						</div>
						<li>Reflect on how easy that was.</li>
					</ol>	
				</div>
				<hr>
				<div id="verify">
					<h2>Verifying Dotbot is really Dotbot</h2>
					<p>From time to time, other crawlers will spoof the Dotbot user-agent to make them seem legitimate. Luckily, the Internet provides a process (DNS lookup) for verifying that the Dotbot that visits your website is actually from dotnetdotcom.org rather than some spammy scumbag named Steve. (Damn You Steve!)</p>
					<h3>The Verification Process</h3>
					<ol>
						<li>Do a reverse DNS lookup on the IP address that crawled your server</li>
<pre><code>
	nslookup 88.888.88.88
</code></pre>
						<li>Find the <strong>name</strong> field and verify that it is on the dotnetdotcom.org domain. Note that the subdomain may vary.</li>
						<li>Do a forward DNS Lookup on the hostname</li>
<pre><code>
	nslookup crawl1.dotnetdotcom.org
</code></pre>
						<li>Verify that the <strong>Address</strong> field has the same value as the IP that crawled you</li>
					</ol>	
						<p>Note: We don't publicly publish our crawling IP address because they tend to change from time to time. The best way to <a href="#info">block us</a> is always robots.txt via our user-agent, Dotbot.</p>
				</div>
				<hr>		
				<div id="purpose">
					<h2>Our Purpose and Goal</h2>
					<p>Our purpose is rather simple. We want to make the internet as open as possible. Currently only a select few corporations have a complete and useful index of the web. Our goal is to change that fact by crawling the web and releasing as much information about its structure and content as possible. We plan on doing this in a manner that will cover our costs (selling our index) and releasing it for free for the benefit of all webmasters. Obviously, this goal has many potential legal, financial, ethical and technical problems. So while we can't promise specific results, we can promise to work hard, share our results, and help make the internet a better and more open space. </p>

					<p>View our preliminary <a href="#stat">internet statistics</a> and <a href="#inde">free downloadable index</a> below</p>
				</div>
				<hr>
				<div id="tech">
					<h2>Our Technology</h2>
					<p>Our crawling system is written in a mixture of C and Python. We elected to store our index using custom flat files on disk as opposed to a traditional database management system. We would like to give thanks to everyone who was involved in the many open source tools we used. These include gcc, gdb, ubuntu linux, valgrind, python and libcurl. Additionally, we want to thank the many webmasters who have taken the time to give us feedback and support our cause. Thank You!</p>
				</div>
				<hr>
				<div id="inde">
					<h2>Downloadable Index of the Internet</h2>
					<p>[Updated on April 21st, 2009. Our old torrent setup was not working well enough (the file was much too large and the connection was too slow) so we switched over to Amazon S3. Luckily for us, they can serve the file as a torrent (Pretty cool, right?) We have broken the index into smaller parts so it should be much easier to digest now.</p>
					<p>We believe the internet should be open to everyone. Currently, only a select few corporations have access to an index of the world wide web. Our intention is to change that.</p>
					<p>We invite you to help us share the content of internet by downloading the first part of our index. It has roughly 600,000 pages and is shared in an easy to parse text file. We are making this available as a bit torrent to help conserve bandwidth. Enjoy!</p>
					<a href="http://webcrawl.s3.amazonaws.com/web200904.gz?torrent">Download our index (Warning: File size is approximately 3.2 Gigabytes compressed and about 14 Gigabytes uncompressed)</a>
<br/>
					<h3>Index Format and Sample File</h3>
					<p>Confused? The information below explains how the index is formatted and includes a small sample index file. (It also uses the little known HTML &lt;code&gt; tag!)</p>
					<h4>Format</h4>
					<p>The overall format is:</p>
<pre><code>				
	Entry NULL Entry NULL Entry
</code></pre>			
					<p>Each entry has the format:</p>
<pre><code>	
	URL-Without-Protocol NULL Optional-String-Not-Used NULL
	Complete-HTTP-Response NULL
</code></pre>
					<p>Key:</p>
					<ul>
						<li>NULL = Zero Byte</li>
						<li>url-without-protocol = www.example.com/</li>
						<li>optional-string-not-used = Currently planned for future use</li>
						<li>complete-HTTP-response = The complete HTTP response</li>
					</ul>
					<p>The following is an example of two entries:</p>			
<pre><code>
	www.example.com/  HTTP/1.1 200 OK
	Date: Sat, 20 Sep 2008 15:43:15 GMT
	Server: Apache/2.0.52 (CentOS)
	X-Powered-By: PHP/4.3.9
	Content-Length: 557
	Connection: close
	Content-Type: text/html; charset=UTF-8			

	&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
	&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"&gt;
	&lt;head&gt;
	&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
	&lt;title&gt;I am an example.&lt;/title&gt;
	&lt;/head&gt;
	&lt;body&gt;
	...
	&lt;body&gt;
	&lt;/html&gt; www.example2.com/  HTTP/1.1 200 OK
	Date: Sat, 20 Sep 2008 15:43:15 GMT
	Server: Apache/2.0.52 (CentOS)
	X-Powered-By: PHP/4.3.9
	Content-Length: 557
	Connection: close
	Content-Type: text/html; charset=UTF-8			

	&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
	&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"&gt;
	&lt;head&gt;
	&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
	&lt;title&gt;I am a different example.&lt;/title&gt;
	&lt;/head&gt;
	&lt;body&gt;
	...
	&lt;body&gt;
	&lt;/html&gt;

</code></pre>
					<h4>Sample File</h4>
					<p>Not ready for the whole thing? No problem! Here is a small sample of the index so you can get an idea of how the giant text files are formatted.</p>
					<a href="http://www.dotnetdotcom.org/web.short.gz">Download our sample index (File size is approximately 2 Megabytes!)</a>

					<h4>A Note On Crawl Quality</h4>
					<p>The downloadable index above contains a uniform sample of pages. We're trying to keep this updated as we crawl new pages, but as you can imagine it's a little bit tricky :)  The data is roughly as fresh as two to three months.  The oldest pages might be four months old; the newest might be weeks old. Also due to our crawling method, Our crawl is probably biased toward English speaking sites within the US. Lo siento, mi amigos ;-)</p>

				</div>		



				<script type="text/javascript">

				/***********************************************
				*			Real Time Statistics
				***********************************************/

				function dcountup(startingdate, baseunit){
					this.currentTime=new Date()
					this.startingdate=new Date(startingdate)
					this.timesup=false
					this.baseunit=baseunit
					this.start()
				}

				dcountup.prototype.oncountup=function(){} //default action

				dcountup.prototype.start=function(){
					var thisobj=this
					this.currentTime.setSeconds(this.currentTime.getSeconds()+1)
					var timediff=Math.floor((this.currentTime-this.startingdate)/1000) //difference between starting date and current date, in seconds
					var oneMinute=60 //minute in seconds
					var oneHour=60*60 //hour in seconds
					var oneDay=60*60*24 //day in seconds
					var dayfield=Math.floor(timediff/oneDay)
					var hourfield=Math.floor((timediff-dayfield*oneDay)/oneHour)
					var minutefield=Math.floor((timediff-dayfield*oneDay-hourfield*oneHour)/oneMinute)
					var secondfield=Math.floor((timediff-dayfield*oneDay-hourfield*oneHour-minutefield*oneMinute))

					//offsets to make data more accurate
					var domainOffset=230000000
					var pageOffset=44000000000
					var robotsOffset=2000000

					if (this.baseunit=="tubes"){ //if tubes
						secondfield=Math.floor(dayfield*1337+(timediff/3))
						dayfield=hourfield=minutefield="n/a"
					}
					else if (this.baseunit=="domains"){ //if domains
						secondfield=Math.floor(domainOffset+(timediff/42))
						dayfield=hourfield=minutefield="n/a"
					}
					else if (this.baseunit=="robots"){ //if robots
						secondfield=Math.floor(robotsOffset+timediff/(42*3.14))
						dayfield=hourfield=minutefield="n/a"
					}
					else if (this.baseunit=="pages"){ //if pages
						secondfield=Math.floor(pageOffset+timediff+(secondfield*(							3141.592653589793238462643383279/2)
							))
						dayfield=hourfield=minutefield="n/a"
					}
					var result={days: dayfield, hours:hourfield, minutes:minutefield, seconds:secondfield}
					this.oncountup(result)
					setTimeout(function(){thisobj.start()}, 1000) //update results every second
				}

				</script>
				<hr>
				<div id="stat">
					<h2>Internet Statistics</h2>
					<p>Please be aware that these are merely an aggregate of what we have crawled so far AND only the very
						beginning of the type of internet data we will be sharing. Future data will be much more specific, much more comprehensive and much more downloadable.</p>

						<h3>HTTP Statuses</h3>
						<center><img src="img/http-graph.png" alt="HTTP Statuses"></center>
						<table border="1" cellspacing="5" cellpadding="5">
							<tr><th>200</th><td>74.77%</td></tr>
							<tr><th>300</th><td>0.01%</td></tr>
							<tr><th>301</th><td>4.86%</td></tr>
							<tr><th>302</th><td>11.48%</td></tr>
							<tr><th>303</th><td>0.07%</td></tr>
							<tr><th>307</th><td>0.01%</td></tr>
							<tr><th>400</th><td>0.76%</td></tr>
							<tr><th>401</th><td>0.07%</td></tr>
							<tr><th>403</th><td>0.62%</td></tr>
							<tr><th>404</th><td>6.63%</td></tr>
							<tr><th>406</th><td>0.01%</td></tr>
							<tr><th>410</th><td>0.03%</td></tr>
							<tr><th>500</th><td>0.48%</td></tr>
							<tr><th>501</th><td>0.01%</td></tr>
							<tr><th>502</th><td>0.02%</td></tr>
							<tr><th>503</th><td>0.14%</td></tr>
							<tr><th>505</th><td>0.01%</td></tr>
							<tr><th>999</th><td>0.03%</td></tr>
						</table>	

						<h3>Dotbot Spider Statistics</h3>
						<p>Note: These are rough estimations. You can think of them like Ask.com search results. They might not be accurate, but at least they tried. (Oh Snap!)</p>
						<table border="1" cellspacing="5" cellpadding="5">
							<tr><th>Born</th><td>June 10th 2008</td></tr>
							<tr><th># of Domains Crawled</th>
								<td>
									<div id="domains">&nbsp;</div>
									<script type="text/javascript">
									var pages=new dcountup("June 10, 2008 12:00:00", "domains")

									pages.oncountup=function(result){
										var mycontainer=document.getElementById("domains")
										mycontainer.innerHTML=result['seconds'] + "ish"
									}
									</script>
								</td>
							</tr>
							<tr><th># of Pages Crawled</th>
								<td>
									<div id="pages">&nbsp;</div>
									<script type="text/javascript">
									var pages=new dcountup("June 10, 2008 12:00:00", "pages")

									pages.oncountup=function(result){
										var mycontainer=document.getElementById("pages")
										mycontainer.innerHTML=result['seconds'] + "ish"
									}
									</script>
								</td>
							</tr>
							<tr><th># of Robots.txt encountered</th>
								<td>
									<div id="robots">&nbsp;</div>

									<script type="text/javascript">
									var pages=new dcountup("June 10, 2008 12:00:00", "robots")

									pages.oncountup=function(result){
										var mycontainer=document.getElementById("robots")
										mycontainer.innerHTML=result['seconds'] + "ish"
									}
									</script>
								</td>
							</tr>
							<tr><th><a href="http://en.wikipedia.org/wiki/Series_of_tubes" rel="nofollow"># of Tubes Found Clogged</a></th>
								<td>
									<div id="tubes">&nbsp;</div>
									<script type="text/javascript">
									var pages=new dcountup("June 10, 2008 12:00:00", "tubes")

									pages.oncountup=function(result){
										var mycontainer=document.getElementById("tubes")
										mycontainer.innerHTML=result['seconds']
									}
									</script>
								</td>
							</tr>
						</table>
						<br />
					</div>
					<hr>
					<div id="cont">
						<h2>Contact Information</h2>
						<p>Feel free to contact us. We are nice people just like you who enjoy good conversation and the occasional Mojito. We can answer some of your crawling questions but discussion of girlfriend/boyfriend/husband/wife issues are strictly prohibited.</p>
						<ul>
							<li>E-mail:</b> <a href="mailto:admin@dotnetdotcom.org">admin@dotnetdotcom.org</a> (Please include your domain name in your e-mail or we can't help you! <blink>AAhhhh!!!</blink>)</li>
							<li>Phone Number: 1 (206) 299-9628</li>
							</ul>
						</div>
						<hr>
					</div>
				</div>
			</body>
			</html>